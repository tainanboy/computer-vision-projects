{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import sampler\n",
    "import torchvision.datasets as dset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from skimage import io, color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "class ChunkSampler(sampler.Sampler):\n",
    "    \"\"\"Samples elements sequentially from some offset. \n",
    "    Arguments:\n",
    "        num_samples: # of desired datapoints\n",
    "        start: offset where we should start selecting from\n",
    "    \"\"\"\n",
    "    def __init__(self, num_samples, start=0):\n",
    "        self.num_samples = num_samples\n",
    "        self.start = start\n",
    "\n",
    "    def __iter__(self):\n",
    "        return iter(range(self.start, self.start + self.num_samples))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0))) \n",
    "\n",
    "def color2gray(img):\n",
    "    r, g, b = img[:,0,:,:], img[:,1,:,:], img[:,2,:,:]\n",
    "    gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
    "    gray = gray.unsqueeze(1)\n",
    "    return gray  #return batchsize*1*height*width\n",
    "\n",
    "def grayshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    gray = img.cpu().numpy()\n",
    "    plt.imshow(np.transpose(gray, (1, 2, 0)), cmap='gray')\n",
    "    \n",
    "def color2yuv(img):\n",
    "    yuvimages = color.rgb2yuv(np.transpose(img.numpy(), (0, 2, 3, 1)))\n",
    "    yuv = np.transpose(yuvimages, (0, 3, 1, 2))\n",
    "    yuv = torch.from_numpy(yuv)\n",
    "    return yuv\n",
    "\n",
    "def yuv2color(img):\n",
    "    rgbimages = color.yuv2rgb(np.transpose(img.numpy(), (0, 2, 3, 1)))\n",
    "    rgb = np.transpose(rgbimages, (0, 3, 1, 2))\n",
    "    rgb = torch.from_numpy(rgb)\n",
    "    return rgb\n",
    "\n",
    "def gety(yuv):\n",
    "    #yuv is a tensor with batch*3*H*W\n",
    "    #return y with batch*1*H*@\n",
    "    y = yuv[:, 0, :, :]\n",
    "    y = y.unsqueeze(1)\n",
    "    return y\n",
    "\n",
    "def combine_yuv(y, uv):\n",
    "    yuv = torch.cat((y, uv),1)\n",
    "    return yuv\n",
    "\n",
    "def sample_noise(batch_size, dim):\n",
    "    \"\"\"\n",
    "    Generate a PyTorch Tensor of uniform random noise.\n",
    "\n",
    "    Input:\n",
    "    - batch_size: Integer giving the batch size of noise to generate.\n",
    "    - dim: Integer giving the dimension of noise to generate.\n",
    "    \n",
    "    Output:\n",
    "    - A PyTorch Tensor of shape (batch_size, dim) containing uniform\n",
    "      random noise in the range (-1, 1).\n",
    "    \"\"\"\n",
    "    # torch.rand generates in range (0, 1), hence using scale and shift to get to range (-1, 1)\n",
    "    noise = torch.rand(batch_size, dim) * 2.0 - 1.0\n",
    "    return noise\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.size() # read in N, C, H, W\n",
    "        return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image\n",
    "    \n",
    "class Unflatten(nn.Module):\n",
    "    \"\"\"\n",
    "    An Unflatten module receives an input of shape (N, C*H*W) and reshapes it\n",
    "    to produce an output of shape (N, C, H, W).\n",
    "    \"\"\"\n",
    "    def __init__(self, N=-1, C=128, H=7, W=7):\n",
    "        super(Unflatten, self).__init__()\n",
    "        self.N = N\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "    def forward(self, x):\n",
    "        return x.view(self.N, self.C, self.H, self.W)\n",
    "\n",
    "def initialize_weights(m):\n",
    "    if isinstance(m, nn.Linear) or isinstance(m, nn.ConvTranspose2d):\n",
    "        init.xavier_uniform(m.weight.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/tiny-imagenet-200/train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d7299d3adf89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                             transform=transforms.Compose([\n\u001b[1;32m      4\u001b[0m                                 \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                                 \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                             ]))\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/style/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader)\u001b[0m\n\u001b[1;32m     91\u001b[0m     def __init__(self, root, transform=None, target_transform=None,\n\u001b[1;32m     92\u001b[0m                  loader=default_loader):\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda2/envs/style/lib/python3.6/site-packages/torchvision-0.1.9-py3.6.egg/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mfind_classes\u001b[0;34m(dir)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfind_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/tiny-imagenet-200/train'"
     ]
    }
   ],
   "source": [
    "# load dataset \n",
    "trainset = dset.ImageFolder(root='./data/tiny-imagenet-200/train',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "\n",
    "testset =  dset.ImageFolder(root='./data/tiny-imagenet-200/test',\n",
    "                            transform=transforms.Compose([\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                            ]))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtype = torch.FloatTensor\n",
    "#dtype = torch.cuda.FloatTensor ## UNCOMMENT THIS LINE IF YOU'RE ON A GPU!\n",
    "\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1])\n"
     ]
    }
   ],
   "source": [
    "class netD(nn.Module):\n",
    "    def __init__(self, N=batch_size, C=3, H=64, W=64):\n",
    "        super(netD, self).__init__()\n",
    "        self.N = N\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(self.C, self.H, 4, 2, 1, bias=False),\n",
    "                                 nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(self.H, self.H* 2, 4, 2, 1, bias=False),\n",
    "                                 nn.BatchNorm2d(self.H * 2),\n",
    "                                 nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(self.H * 2, self.H * 4, 4, 2, 1, bias=False),\n",
    "                                 nn.BatchNorm2d(self.H * 4),\n",
    "                                 nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(self.H * 4, self.H * 8, 4, 2, 1, bias=False),\n",
    "                                 nn.BatchNorm2d(self.H * 8),\n",
    "                                 nn.LeakyReLU(0.2, inplace=True))\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(self.H * 8, 1, 4, 1, 0, bias=False),\n",
    "                                 nn.Sigmoid())\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x) #64*64*32*32\n",
    "        out = self.layer2(out) #64*128*16*16\n",
    "        out = self.layer3(out) #64*256*8*8\n",
    "        out = self.layer4(out) #64*512*4*4\n",
    "        out = self.layer5(out) #64*1*1*1\n",
    "        out = out.squeeze(2)\n",
    "        out = out.squeeze(2)\n",
    "        return out\n",
    "    \n",
    "D = netD().type(dtype)\n",
    "c = Variable(torch.Tensor(64, 3, 64, 64)).type(dtype) #true\n",
    "out = D(c)\n",
    "print(out.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "class netG(nn.Module):\n",
    "    def __init__(self, N=batch_size, C=2, H=64, W=64, Zdim=96):\n",
    "        super(netG, self).__init__()\n",
    "        self.N = N\n",
    "        self.C = C\n",
    "        self.H = H\n",
    "        self.W = W\n",
    "        self.Z = Zdim\n",
    "        self.project = nn.Linear(Zdim, self.H*self.H)\n",
    "        self.zlayer = nn.Sequential(\n",
    "                                 nn.ReLU(True))\n",
    "        self.layer1 = nn.Sequential(nn.Conv2d(self.C, self.H*2, 7, 1, 3, bias=False),\n",
    "                                 nn.BatchNorm2d(self.H*2),\n",
    "                                 nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Conv2d(self.H*2+2, self.H, 5, 1, 2, bias=False),\n",
    "                                 nn.BatchNorm2d(self.H),\n",
    "                                 nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Conv2d(self.H+2, self.H, 5, 1, 2, bias=False),\n",
    "                                 nn.BatchNorm2d(self.H),\n",
    "                                 nn.ReLU(True))\n",
    "        self.layer4 = nn.Sequential(nn.Conv2d(self.H+1, self.H, 5, 1, 2, bias=False),\n",
    "                                 nn.BatchNorm2d(self.H),\n",
    "                                 nn.ReLU(True))\n",
    "        self.layer5 = nn.Sequential(nn.Conv2d(self.H+1, int(self.H/2), 5, 1, 2, bias=False),\n",
    "                                 nn.BatchNorm2d(int(self.H/2)),\n",
    "                                 nn.ReLU(True))\n",
    "        self.layer6 = nn.Sequential(nn.Conv2d(int(self.H/2)+1, 2, 5, 1, 2, bias=False),\n",
    "                                 nn.BatchNorm2d(2),\n",
    "                                 nn.ReLU(True))\n",
    "        \n",
    "    \n",
    "    def forward(self, x, z):\n",
    "        #project z \n",
    "        z = self.project(z)\n",
    "        z = z.view(batch_size, 1, self.H, self.H)\n",
    "        z = self.zlayer(z)\n",
    "        out = torch.cat((x, z),1)\n",
    "        out = self.layer1(out) #64*128*64*64\n",
    "        out = torch.cat((x, out),1)\n",
    "        out = torch.cat((out, z),1)\n",
    "        out = self.layer2(out) #64*64*64*64\n",
    "        out = torch.cat((x, out),1)\n",
    "        out = torch.cat((out, z),1)\n",
    "        out = self.layer3(out) #64*64*64*64\n",
    "        out = torch.cat((x, out),1)\n",
    "        out = self.layer4(out) #64*64*64*64\n",
    "        out = torch.cat((x, out),1)\n",
    "        out = self.layer5(out) #64*32*64*64\n",
    "        out = torch.cat((x, out),1)\n",
    "        out = self.layer6(out) #64*2*64*64\n",
    "        out = torch.cat((x, out),1)\n",
    "        return out\n",
    "\n",
    "G = netG().type(dtype)\n",
    "c = Variable(torch.Tensor(64, 1, 64, 64)).type(dtype)\n",
    "z = Variable(sample_noise(batch_size, dim=96)).type(dtype)\n",
    "#print(z.size())\n",
    "out = G(c, z)\n",
    "print(out.size()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def g_optimizer(model):\n",
    "    \"\"\"\n",
    "    Construct and return an Adam optimizer for the model with learning rate 1e-3,\n",
    "    beta1=0.5, and beta2=0.999.\n",
    "    \n",
    "    Input:\n",
    "    - model: A PyTorch model that we want to optimize.\n",
    "    \n",
    "    Returns:\n",
    "    - An Adam optimizer for the model with the desired hyperparameters.\n",
    "    \"\"\"\n",
    "    optimizer = optim.Adam(model.parameters(), lr=2e-4, betas=(0.5, 0.999))\n",
    "    return optimizer\n",
    "\n",
    "def d_optimizer(model):\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bce_loss(input, target):\n",
    "    \"\"\"\n",
    "    Numerically stable version of the binary cross-entropy loss function.\n",
    "\n",
    "    As per https://github.com/pytorch/pytorch/issues/751\n",
    "    See the TensorFlow docs for a derivation of this formula:\n",
    "    https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits\n",
    "\n",
    "    Inputs:\n",
    "    - input: PyTorch Variable of shape (N, ) giving scores.\n",
    "    - target: PyTorch Variable of shape (N,) containing 0 and 1 giving targets.\n",
    "\n",
    "    Returns:\n",
    "    - A PyTorch Variable containing the mean BCE loss over the minibatch of input data.\n",
    "    \"\"\"\n",
    "    # bce_loss(input, target) = target * -log(sigmoid(input)) + (1 - target) * -log(1 - sigmoid(input))\n",
    "    \n",
    "    neg_abs = - input.abs()\n",
    "    loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 2.6844e+08\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def discriminator_loss(logits_real, logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the discriminator loss described above.\n",
    "    \n",
    "    Inputs:\n",
    "    - logits_real: PyTorch Variable of shape (N,) giving scores for the real data.\n",
    "    - logits_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Variable containing (scalar) the loss for the discriminator.\n",
    "    \"\"\"\n",
    "    N_real = logits_real.size()\n",
    "    N_fake = logits_fake.size()\n",
    "    \n",
    "    true_labels = Variable(torch.ones(N_real)).type(dtype)\n",
    "    false_labels = Variable(torch.zeros(N_fake)).type(dtype)\n",
    "    \n",
    "    loss_real = bce_loss(logits_real, true_labels)\n",
    "    loss_fake = bce_loss(logits_fake, false_labels)\n",
    "    \n",
    "    loss = loss_real + loss_fake\n",
    "    return loss\n",
    "\n",
    "tlogits_real = Variable(torch.Tensor(64, 1)).type(dtype)\n",
    "tlogits_fake = Variable(torch.Tensor(64, 1)).type(dtype)\n",
    "discriminator_loss(tlogits_real, tlogits_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 5.7660e+17\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generator_loss(logits_fake, fake_img, real_img, L1weight=10):\n",
    "    \"\"\"\n",
    "    Computes the generator loss described above.\n",
    "\n",
    "    Inputs:\n",
    "    - logits_fake: PyTorch Variable of shape (N,) giving scores for the fake data.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Variable containing the (scalar) loss for the generator.\n",
    "    \"\"\"\n",
    "    N = logits_fake.size()\n",
    "    fake_true_labels = Variable(torch.ones(N)).type(dtype)\n",
    "    \n",
    "    fkv = fake_img.view(batch_size, 3, 64, 64)\n",
    "    rv = real_img.view(batch_size, 3, 64, 64)\n",
    "    l = torch.abs(fkv - rv)\n",
    "    #g_fkv = color2gray(fake_img.view(batch_size, 3, 64, 64))\n",
    "    #g_rv =  color2gray(real_img.view(batch_size, 3, 64, 64))\n",
    "    #l = torch.abs(g_fkv - g_rv)\n",
    "    l1loss = l.sum()/(batch_size*1*64*64)\n",
    "\n",
    "    #loss = bce_loss(logits_fake, fake_true_labels) + l1loss*L1weight\n",
    "    loss = bce_loss(logits_fake, fake_true_labels)\n",
    "    return loss\n",
    "\n",
    "logits_fake = Variable(torch.Tensor(batch_size, 1)).type(dtype)\n",
    "fake_img = torch.Tensor(batch_size, 3, 64, 64).type(dtype)\n",
    "real_img = torch.Tensor(batch_size, 3, 64, 64).type(dtype)\n",
    "generator_loss(logits_fake, fake_img, real_img, 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pytorch_plot_losses(softmax_loss_history=None, mse_loss_history=None, \n",
    "                                        test_losses_softmax=None, test_losses_mse=None):\n",
    "    plt.clf()\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    if softmax_loss_history:\n",
    "        ax1.plot(softmax_loss_history, color=\"blue\")\n",
    "    if test_losses_softmax:\n",
    "        ax1.plot(test_losses_softmax, color=\"green\")\n",
    "    ax2 = ax1.twinx()\n",
    "    if mse_loss_history:\n",
    "        ax2.plot(mse_loss_history, color=\"red\")\n",
    "    if test_losses_mse:\n",
    "        ax2.plot(test_losses_mse, color=\"black\")\n",
    "    #ax2.set_yscale('log')\n",
    "    plt.savefig('imagenet_output_losses.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_a_gan(D, G, D_solver, G_solver, dscriminator_loss, generator_loss, show_every=250, \n",
    "              batch_size=64, noise_size=96, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train a GAN!\n",
    "    \n",
    "    Inputs:\n",
    "    - D, G: PyTorch models for the discriminator and generator\n",
    "    - D_solver, G_solver: torch.optim Optimizers to use for training the\n",
    "      discriminator and generator.\n",
    "    - discriminator_loss, generator_loss: Functions to use for computing the generator and\n",
    "      discriminator loss, respectively.\n",
    "    - show_every: Show samples after every show_every iterations.\n",
    "    - batch_size: Batch size to use for training.\n",
    "    - noise_size: Dimension of the noise to use as input to the generator.\n",
    "    - num_epochs: Number of epochs over the training dataset to use for training.\n",
    "    \"\"\"\n",
    "    D_losses = []\n",
    "    epoch_D_losses = []\n",
    "    G_losses = []\n",
    "    epoch_G_losses = []\n",
    "    iter_count = 0\n",
    "    for epoch in range(num_epochs):\n",
    "        for x, _ in trainloader:\n",
    "            if len(x) != batch_size:\n",
    "                continue\n",
    "            # update D\n",
    "            D_solver.zero_grad()\n",
    "            input_rgb = Variable(x).type(dtype)\n",
    "            input_yuv = Variable(color2yuv(x)).type(dtype)\n",
    "            input_y = Variable(gety(input_yuv.data)).type(dtype)\n",
    "            logits_real = D(2* (input_rgb - 0.5)).type(dtype)\n",
    "            noise_seed = Variable(sample_noise(batch_size, noise_size)).type(dtype)\n",
    "            \n",
    "            fake_yuv = G(input_y, noise_seed).detach()\n",
    "            fake_rgb = Variable(yuv2color(fake_yuv.data)).type(dtype)\n",
    "            logits_fake = D(fake_rgb.view(batch_size, 4, 64, 64))\n",
    "\n",
    "            d_total_error = discriminator_loss(logits_real, logits_fake)\n",
    "            d_total_error.backward()        \n",
    "            D_solver.step()\n",
    "            \n",
    "            #update G\n",
    "            G_solver.zero_grad()\n",
    "            input_y = Variable(gety(input_yuv.data)).type(dtype)\n",
    "            noise_seed = Variable(sample_noise(batch_size, noise_size)).type(dtype)\n",
    "            fake_yuv = G(input_y, noise_seed).detach()\n",
    "            fake_rgb = Variable(yuv2color(fake_yuv.data)).type(dtype)\n",
    "            \n",
    "            gen_logits_fake = D(fake_rgb.view(batch_size, 4, 64, 64))\n",
    "            \n",
    "            g_error = generator_loss(gen_logits_fake, fake_images, input_rgb, 0.05)\n",
    "            g_error.backward()\n",
    "            G_solver.step()\n",
    "            \n",
    "            #plot\n",
    "            D_losses.append(d_total_error.cpu().data.numpy()[0])\n",
    "            G_losses.append(g_error.cpu().data.numpy()[0])\n",
    "            \n",
    "            if (iter_count % show_every == 0):\n",
    "                imshow(torchvision.utils.make_grid(x.view(batch_size,3,64,64)))\n",
    "                plt.show()\n",
    "                grayshow(torchvision.utils.make_grid(g_real_data.data.view(batch_size,1,64,64)))\n",
    "                plt.show()\n",
    "                print('Epoch:{}, Iter: {}, D: {:.4}, G:{:.4}'.format(epoch,iter_count,d_total_error.data[0],g_error.data[0]))\n",
    "                imshow(torchvision.utils.make_grid(fake_images.data.view(batch_size,3,64,64)))\n",
    "                plt.show()\n",
    "                print()\n",
    "            iter_count += 1\n",
    "        epoch_D_losses.append(np.mean(D_losses))\n",
    "        epoch_G_losses.append(np.mean(G_losses))\n",
    "    pytorch_plot_losses(softmax_loss_history=epoch_G_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_DC = netD().type(dtype) \n",
    "D_DC.apply(initialize_weights)\n",
    "G_DC = netG().type(dtype)\n",
    "G_DC.apply(initialize_weights)\n",
    "\n",
    "D_DC_solver = d_optimizer(D_DC)\n",
    "G_DC_solver = g_optimizer(G_DC)\n",
    "\n",
    "run_a_gan(D_DC, G_DC, D_DC_solver, G_DC_solver, discriminator_loss, generator_loss, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D_DC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-650fae8d9872>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#save models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mD_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'D_net_imagenet_yuv.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'G_net_imagenet_yuv.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'D_DC' is not defined"
     ]
    }
   ],
   "source": [
    "#save models\n",
    "torch.save(D_DC.state_dict(), 'D_net_imagenet_yuv.pkl')\n",
    "torch.save(G_DC.state_dict(), 'G_net_imagenet_yuv.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'D_DC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-2461315fc3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# test models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mD_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'D_net_imagenet_yuv.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mG_DC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'G_net_imagenet_yuv.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'D_DC' is not defined"
     ]
    }
   ],
   "source": [
    "# test models\n",
    "D_DC.load_state_dict(torch.load('D_net_imagenet_yuv.pkl'))\n",
    "G_DC.load_state_dict(torch.load('G_net_imagenet_yuv.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aa0d4389a23c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# get some random testing images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# show images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testloader' is not defined"
     ]
    }
   ],
   "source": [
    "# get some random testing images\n",
    "timages = testloader.__iter__().next()[0]\n",
    "print(timages.size())\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(timages))\n",
    "plt.show()\n",
    "\n",
    "#show gray images\n",
    "tgray = color2gray(timages)\n",
    "print(tgray.size())\n",
    "grayshow(torchvision.utils.make_grid(tgray))\n",
    "plt.show()\n",
    "\n",
    "tgray = Variable(tgray).type(dtype)\n",
    "gimg = G_DC(tgray).data.view(batch_size, 3, 64, 64)\n",
    "imshow(torchvision.utils.make_grid(gimg))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
